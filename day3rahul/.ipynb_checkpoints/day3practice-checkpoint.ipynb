{
 "metadata": {
  "name": "",
  "signature": "sha256:39c9a3f60d310c035c2ecd3ae66203fe2bf375c7351d08f7166c61ecc5721f69"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time, requests"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we'll just repeat what we did last time to make sure we have all our ducks (erm files) lined up. Its a good idea to split each analysis stage up separately and write out files,so that you are (a) generally working with local files and (b) can restart when some part of the process goes wrong from an intermediate point and not have to fetch data again...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "URLSTART=\"https://www.goodreads.com\"\n",
      "BESTBOOKS=\"/list/show/1.Best_Books_Ever?page=\"\n",
      "for i in xrange(1,3):\n",
      "    bookpage=str(i)\n",
      "    stuff=requests.get(URLSTART+BESTBOOKS+bookpage)\n",
      "    filetowrite=\"page\"+ '%02d' % i + \".html\"\n",
      "    print \"FTW\", filetowrite\n",
      "    fd=open(filetowrite,\"w\")\n",
      "    fd.write(stuff.text.encode('utf-8'))\n",
      "    fd.close()\n",
      "    time.sleep(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW page01.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " page02.html\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyquery import PyQuery as pq\n",
      "bookdict={}\n",
      "for i in xrange(1,3):\n",
      "    books=[]\n",
      "    stri = '%02d' % i\n",
      "    filetoread=\"page\"+ stri + '.html'\n",
      "    print \"FTW\", filetoread\n",
      "    d=pq(filename=filetoread)\n",
      "    for e in d('.bookTitle'):\n",
      "        books.append(pq(e).attr.href)\n",
      "    print books[:10]\n",
      "    bookdict[stri]=books\n",
      "    fd=open(\"list\"+stri+\".txt\",\"w\")\n",
      "    fd.write(\"\\n\".join(books))\n",
      "    fd.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW page01.html\n",
        "['/book/show/2767052-the-hunger-games', '/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix', '/book/show/41865.Twilight', '/book/show/2657.To_Kill_a_Mockingbird', '/book/show/1885.Pride_and_Prejudice', '/book/show/18405.Gone_with_the_Wind', '/book/show/11127.The_Chronicles_of_Narnia', '/book/show/7613.Animal_Farm', '/book/show/370493.The_Giving_Tree', '/book/show/11.The_Hitchhiker_s_Guide_to_the_Galaxy']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "FTW page02.html\n",
        "['/book/show/24583.The_Adventures_of_Tom_Sawyer', '/book/show/34.The_Fellowship_of_the_Ring', '/book/show/6310.Charlie_and_the_Chocolate_Factory', '/book/show/4948.The_Very_Hungry_Caterpillar', '/book/show/9717.The_Unbearable_Lightness_of_Being', '/book/show/6900.Tuesdays_with_Morrie', '/book/show/1423.The_Compleat_Works_of_Wllm_Shkspr', '/book/show/12296.The_Scarlet_Letter', '/book/show/256008.Lonesome_Dove', '/book/show/10365.Where_the_Red_Fern_Grows']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok so now lets dive in and get one of these these files and parse them. Lets go get the Tom Sayer url."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomurl=URLSTART+bookdict['02'][0]\n",
      "tomurl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "'https://www.goodreads.com/book/show/24583.The_Adventures_of_Tom_Sawyer'"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomstuff=requests.get(tomurl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tomstuff.text[:500]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "u'<!DOCTYPE html>\\n<html class=\"desktop\">\\n\\n\\n<head prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# good_reads: http://ogp.me/ns/fb/good_reads#\">\\n  <meta name=\"google-site-verification\" content=\"PfFjeZ9OK1RrUrKlmAPn_iZJ_vgHaZO1YQ-QlG2VsJs\" />\\n\\n  <title>The Adventures of Tom Sawyer by Mark Twain \\u2014 Reviews, Discussion, Bookclubs, Lists</title>\\n    <meta property=\"og:title\" content=\"The Adventures of Tom Sawyer\"/>\\n  <meta property=\"og:type\"  content=\"good_reads:book\"/>\\n  <meta property=\"og:url\" c'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets get everything we want..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d=pq(tomstuff.text)\n",
      "print d(\"meta[property='og:title']\").attr('content')\n",
      "print d(\"meta[property='good_reads:isbn']\").attr('content')\n",
      "print d(\"meta[property='og:type']\").attr('content')\n",
      "print d(\"meta[property='good_reads:author']\").attr('content')\n",
      "print d(\"span.average\").text()\n",
      "print d(\"span.value-title[itemprop='ratingCount']\").attr(\"title\")\n",
      "print d(\"span.value-title[itemprop!='ratingCount']\").attr(\"title\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Adventures of Tom Sawyer\n",
        "0143039563\n",
        "good_reads:book\n",
        "https://www.goodreads.com/author/show/1244.Mark_Twain\n",
        "3.86\n",
        "387993\n",
        "4471\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now that we know what to do, lets wrap our fetching into a proper script. So that we dont overwhelm their servers, we will only fetch 5 from each page, but you get the idea..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fetched=[]\n",
      "for i in xrange(1,3):\n",
      "    stri = '%02d' % i\n",
      "    with open(\"list\"+stri+\".txt\") as fd:\n",
      "        counter=0\n",
      "        for bookurl_line in fd:\n",
      "            if counter > 4:\n",
      "                break\n",
      "            bookurl=bookurl_line.strip()\n",
      "            stuff=requests.get(URLSTART+bookurl)\n",
      "            filetowrite=bookurl.split('/')[-1]\n",
      "            filetowrite=stri+\"_\"+filetowrite+\".html\"\n",
      "            print \"FTW\", filetowrite\n",
      "            fd=open(filetowrite,\"w\")\n",
      "            fd.write(stuff.text.encode('utf-8'))\n",
      "            fd.close()\n",
      "            fetched.append(filetowrite)\n",
      "            time.sleep(2)\n",
      "            counter=counter+1\n",
      "            \n",
      "print fetched"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "FTW 01_2767052-the-hunger-games.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_2.Harry_Potter_and_the_Order_of_the_Phoenix.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_41865.Twilight.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_2657.To_Kill_a_Mockingbird.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_1885.Pride_and_Prejudice.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_18405.Gone_with_the_Wind.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_11127.The_Chronicles_of_Narnia.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_7613.Animal_Farm.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_370493.The_Giving_Tree.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 01_11.The_Hitchhiker_s_Guide_to_the_Galaxy.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_24583.The_Adventures_of_Tom_Sawyer.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_34.The_Fellowship_of_the_Ring.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_6310.Charlie_and_the_Chocolate_Factory.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_4948.The_Very_Hungry_Caterpillar.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_9717.The_Unbearable_Lightness_of_Being.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_6900.Tuesdays_with_Morrie.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_1423.The_Compleat_Works_of_Wllm_Shkspr.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_12296.The_Scarlet_Letter.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_256008.Lonesome_Dove.html\n",
        "FTW"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 02_10365.Where_the_Red_Fern_Grows.html\n",
        "['01_2767052-the-hunger-games.html', '01_2.Harry_Potter_and_the_Order_of_the_Phoenix.html', '01_41865.Twilight.html', '01_2657.To_Kill_a_Mockingbird.html', '01_1885.Pride_and_Prejudice.html', '01_18405.Gone_with_the_Wind.html', '01_11127.The_Chronicles_of_Narnia.html', '01_7613.Animal_Farm.html', '01_370493.The_Giving_Tree.html', '01_11.The_Hitchhiker_s_Guide_to_the_Galaxy.html', '02_24583.The_Adventures_of_Tom_Sawyer.html', '02_34.The_Fellowship_of_the_Ring.html', '02_6310.Charlie_and_the_Chocolate_Factory.html', '02_4948.The_Very_Hungry_Caterpillar.html', '02_9717.The_Unbearable_Lightness_of_Being.html', '02_6900.Tuesdays_with_Morrie.html', '02_1423.The_Compleat_Works_of_Wllm_Shkspr.html', '02_12296.The_Scarlet_Letter.html', '02_256008.Lonesome_Dove.html', '02_10365.Where_the_Red_Fern_Grows.html']"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets parse each item we fetched. The code to get the year is complex..see the shakespeare case as to why. For now dont worry about understanding the else part: that is homework..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "yearre = r'\\d{4}'\n",
      "listofdicts=[]\n",
      "for filetoread in fetched:\n",
      "    td={}\n",
      "    d=pq(filename=filetoread)\n",
      "    td['title']=d(\"meta[property='og:title']\").attr('content')\n",
      "    td['isbn']=d(\"meta[property='good_reads:isbn']\").attr('content')\n",
      "    td['booktype']=d(\"meta[property='og:type']\").attr('content')\n",
      "    td['author']=d(\"meta[property='good_reads:author']\").attr('content')\n",
      "    td['rating']=d(\"span.average\").text()\n",
      "    td['ratingCount']=d(\"span.value-title[itemprop='ratingCount']\").attr(\"title\")\n",
      "    td['reviewCount']=d(\"span.value-title[itemprop!='ratingCount']\").attr(\"title\")\n",
      "    if d(\"nobr.greyText\").text().strip()!=\"\":\n",
      "        td['year']=d(\"nobr.greyText\").text().strip().split()[-1][:-1]\n",
      "    else:\n",
      "        thetext=d(\"div#details div.row\").eq(1).text().strip()\n",
      "        rowmatch=re.findall(yearre, thetext)\n",
      "        if len(rowmatch) > 0:\n",
      "            rowtext=rowmatch[0].strip()\n",
      "        else:\n",
      "            rowtext=\"NA\"\n",
      "        td['year']=rowtext\n",
      "    td['file']=filetoread\n",
      "    genres=d(\"div.elementList div.left a\")\n",
      "    glist=[]\n",
      "    for g in genres:\n",
      "        glist.append(d(g).attr('href'))\n",
      "    td['genres']=\"|\".join(glist)\n",
      "    listofdicts.append(td)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listofdicts[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "{'author': 'https://www.goodreads.com/author/show/153394.Suzanne_Collins',\n",
        " 'booktype': 'good_reads:book',\n",
        " 'file': '01_2767052-the-hunger-games.html',\n",
        " 'genres': '/genres/young-adult|/genres/fiction|/genres/science-fiction|/genres/dystopia|/genres/fantasy|/genres/science-fiction|/genres/romance|/genres/adventure|/genres/book-club|/genres/young-adult|/genres/teen|/genres/apocalyptic|/genres/post-apocalyptic',\n",
        " 'isbn': '0439023483',\n",
        " 'rating': '4.40',\n",
        " 'ratingCount': '2977377',\n",
        " 'reviewCount': '136657',\n",
        " 'title': 'The Hunger Games (The Hunger Games, #1)',\n",
        " 'year': '2008'}"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally lets write all this stuff into a csv file which we will use to do analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "f = open('meta.csv','w')\n",
      "w = csv.DictWriter(f,listofdicts[0].keys())\n",
      "for i,D in enumerate(listofdicts):\n",
      "    listofdicts[i]={k:('None' if v==None else v.encode(\"utf-8\")) for k,v in D.items()}\n",
      "w.writerows(listofdicts)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}